{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AScit-Dr3as"
      },
      "source": [
        "# **Modelo MLP con `PySpark`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8RVc520agvw",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4smZDrXp-sNM",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# INSTALACIÓN Y CONFIGURACIÓN\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7DDo8VLp8AN",
        "notebookRunGroups": {
          "groupValue": "2"
        },
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# Librerias\n",
        "import time\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler, Imputer\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import col, when\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.0-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMrXv24zuhFh",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from pyspark.ml.functions import vector_to_array\n",
        "except Exception:\n",
        "    from pyspark.sql.functions import vector_to_array  # fallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KEi3_PKar2Y",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# Iniciar sesión Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"MyMini\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGl9WRdcAVPA",
        "outputId": "324a7718-79d1-4a65-dacc-69f6eabd3b8f",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recursos Colab:\n",
            "   • RAM total: 12.7 GB\n",
            "   • RAM disponible: 11.0 GB\n",
            "   • Cores CPU: 2\n",
            "   • Spark cores: 2\n"
          ]
        }
      ],
      "source": [
        "# MONITOREO DE RECURSOS\n",
        "def check_colab_resources():\n",
        "    \"\"\"Verificar recursos disponibles en Colab\"\"\"\n",
        "    import psutil\n",
        "    memory = psutil.virtual_memory()\n",
        "    print(f\"Recursos Colab:\")\n",
        "    print(f\"   • RAM total: {memory.total / (1024**3):.1f} GB\")\n",
        "    print(f\"   • RAM disponible: {memory.available / (1024**3):.1f} GB\")\n",
        "    print(f\"   • Cores CPU: {os.cpu_count()}\")\n",
        "    print(f\"   • Spark cores: {spark.sparkContext.defaultParallelism}\")\n",
        "\n",
        "check_colab_resources()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l684sCLzEFoW"
      },
      "source": [
        "### Funciones de evaluación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llxrOWGmDCC4",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "def evaluate_model_comprehensive(model, train_df, test_df, labelCol=\"label\"):\n",
        "    \"\"\"\n",
        "    Evaluación completa del modelo con múltiples métricas\n",
        "    en ambos conjuntos de entrenamiento y prueba\n",
        "    \"\"\"\n",
        "\n",
        "    # Hacer predicciones\n",
        "    train_predictions = model.transform(train_df)\n",
        "    test_predictions = model.transform(test_df)\n",
        "\n",
        "    # Evaluadores para métricas binarias\n",
        "    evaluator_auc_roc = BinaryClassificationEvaluator(\n",
        "        labelCol=labelCol,\n",
        "        rawPredictionCol=\"rawPrediction\",\n",
        "        metricName=\"areaUnderROC\"\n",
        "    )\n",
        "    evaluator_auc_pr = BinaryClassificationEvaluator(\n",
        "        labelCol=labelCol,\n",
        "        rawPredictionCol=\"rawPrediction\",\n",
        "        metricName=\"areaUnderPR\"\n",
        "    )\n",
        "    # Evaluadores para métricas multiclase\n",
        "    evaluator_f1 = MulticlassClassificationEvaluator(\n",
        "        labelCol=labelCol,\n",
        "        predictionCol=\"prediction\",\n",
        "        metricName=\"f1\"\n",
        "    )\n",
        "    evaluator_precision = MulticlassClassificationEvaluator(\n",
        "        labelCol=labelCol,\n",
        "        predictionCol=\"prediction\",\n",
        "        metricName=\"weightedPrecision\"\n",
        "    )\n",
        "    evaluator_recall = MulticlassClassificationEvaluator(\n",
        "        labelCol=labelCol,\n",
        "        predictionCol=\"prediction\",\n",
        "        metricName=\"weightedRecall\"\n",
        "    )\n",
        "    evaluator_accuracy = MulticlassClassificationEvaluator(\n",
        "        labelCol=labelCol,\n",
        "        predictionCol=\"prediction\",\n",
        "        metricName=\"accuracy\"\n",
        "    )\n",
        "\n",
        "    # Calcular métricas para TRAIN\n",
        "    train_auc_roc = evaluator_auc_roc.evaluate(train_predictions)\n",
        "    train_auc_pr = evaluator_auc_pr.evaluate(train_predictions)\n",
        "    train_f1 = evaluator_f1.evaluate(train_predictions)\n",
        "    train_precision = evaluator_precision.evaluate(train_predictions)\n",
        "    train_recall = evaluator_recall.evaluate(train_predictions)\n",
        "    train_accuracy = evaluator_accuracy.evaluate(train_predictions)\n",
        "\n",
        "    # Calcular métricas para TEST\n",
        "    test_auc_roc = evaluator_auc_roc.evaluate(test_predictions)\n",
        "    test_auc_pr = evaluator_auc_pr.evaluate(test_predictions)\n",
        "    test_f1 = evaluator_f1.evaluate(test_predictions)\n",
        "    test_precision = evaluator_precision.evaluate(test_predictions)\n",
        "    test_recall = evaluator_recall.evaluate(test_predictions)\n",
        "    test_accuracy = evaluator_accuracy.evaluate(test_predictions)\n",
        "\n",
        "    # Calcular matriz de confusión para test\n",
        "    confusion_matrix = test_predictions.groupBy(\n",
        "        F.col(labelCol).alias(\"Actual\"),\n",
        "        F.col(\"prediction\").alias(\"Predicted\")\n",
        "    ).count().orderBy(\"Actual\", \"Predicted\")\n",
        "\n",
        "    return {\n",
        "        'train_metrics': {\n",
        "            'AUC_ROC': train_auc_roc,\n",
        "            'AUC_PR': train_auc_pr,\n",
        "            'F1': train_f1,\n",
        "            'Precision': train_precision,\n",
        "            'Recall': train_recall,\n",
        "            'Accuracy': train_accuracy\n",
        "        },\n",
        "        'test_metrics': {\n",
        "            'AUC_ROC': test_auc_roc,\n",
        "            'AUC_PR': test_auc_pr,\n",
        "            'F1': test_f1,\n",
        "            'Precision': test_precision,\n",
        "            'Recall': test_recall,\n",
        "            'Accuracy': test_accuracy\n",
        "        },\n",
        "        'confusion_matrix': confusion_matrix\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-D7R4PnDfb5",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# Calcular métricas específicas por clase desde matriz de confusión\n",
        "def calculate_detailed_metrics(confusion_df):\n",
        "    \"\"\"Calcular métricas detalladas por clase desde matriz de confusión\"\"\"\n",
        "    # Asumiendo que las clases son 0.0 y 1.0\n",
        "    try:\n",
        "        tn = confusion_df[(confusion_df['Actual'] == 0.0) & (confusion_df['Predicted'] == 0.0)]['count'].values[0]\n",
        "        fp = confusion_df[(confusion_df['Actual'] == 0.0) & (confusion_df['Predicted'] == 1.0)]['count'].values[0]\n",
        "        fn = confusion_df[(confusion_df['Actual'] == 1.0) & (confusion_df['Predicted'] == 0.0)]['count'].values[0]\n",
        "        tp = confusion_df[(confusion_df['Actual'] == 1.0) & (confusion_df['Predicted'] == 1.0)]['count'].values[0]\n",
        "\n",
        "        precision_1 = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall_1 = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1_1 = 2 * (precision_1 * recall_1) / (precision_1 + recall_1) if (precision_1 + recall_1) > 0 else 0\n",
        "\n",
        "        precision_0 = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
        "        recall_0 = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        f1_0 = 2 * (precision_0 * recall_0) / (precision_0 + recall_0) if (precision_0 + recall_0) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'class_0': {'precision': precision_0, 'recall': recall_0, 'f1': f1_0},\n",
        "            'class_1': {'precision': precision_1, 'recall': recall_1, 'f1': f1_1}\n",
        "        }\n",
        "    except:\n",
        "        return \"No se pudo calcular métricas detalladas\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxyExIzv6R_r"
      },
      "source": [
        "## Encontrar los mejores hiperparámetros\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXgZYXK6XKu"
      },
      "source": [
        "Uso de CrossValidation de 3 folds.\n",
        "Se utilizo el 10% de la data dispobible.\n",
        "\n",
        "La metrica de evaluación fue `areaUnderPR`: 'area bajo la curva presición recall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-H55y_jxxUTa"
      },
      "outputs": [],
      "source": [
        "# 🔹 Lectura de datos [10% de los datos]\n",
        "df = spark.read.csv(\"data_to_model.csv\", header=True, inferSchema=True)\n",
        "df = df.sample(fraction=0.1, seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Configuración inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AR4HKqFz_cd",
        "outputId": "61536b8d-6888-479f-ea7e-beda450e235a",
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variables categóricas: ['motivo_prestamo', 'tipo_vivienda']\n",
            "Variables numéricas: ['monto_aprobado', 'tasa_interes', 'plazo_meses', 'ingreso_anual', 'antiguedad_laboral', 'estado_verif_ingreso', 'promedio_fico', 'anio_apertura_credito', 'cuentas_hipotecarias', 'total_cuentas_credito', 'cuentas_tarjeta_credito', 'saldo_revolvente', 'uso_credito_revolvente', 'limite_credito_total', 'dti', 'meses_ultima_consulta', 'meses_tarjeta_nueva', 'lineas_credito_12m', 'porcentaje_sin_moras', 'moras_2_year', 'monto_total_cobranzas', 'tuvo_acuerdo_pago', 'subcategoria_credito', 'anio_emision_prestamo', 'mes_emision_prestamo']\n"
          ]
        }
      ],
      "source": [
        "# 🔹 Configuración inicial\n",
        "label_col = \"default\"\n",
        "\n",
        "# Detección automática de columnas\n",
        "categorical_cols = [\n",
        "    col for col in df.columns\n",
        "    if df.schema[col].dataType.typeName() == 'string' and col != label_col]\n",
        "numeric_cols = [\n",
        "    col for col in df.columns\n",
        "    if df.schema[col].dataType.typeName() in ['integer', 'double', 'float'] and col != label_col]\n",
        "\n",
        "print(f\"Variables categóricas: {categorical_cols}\")\n",
        "print(f\"Variables numéricas: {numeric_cols}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZuNBNWr0FZb",
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# 🔹 Preprocesamiento\n",
        "\n",
        "# Convertir label a DoubleType y filtrar nulos\n",
        "df = df.withColumn(\"label\", F.col(label_col).cast(DoubleType()))\\\n",
        "       .filter(F.col(\"label\").isNotNull())\n",
        "\n",
        "# Imputación de valores nulos en variables numéricas\n",
        "imputer = Imputer(\n",
        "    inputCols=numeric_cols,\n",
        "    outputCols=[f\"{c}_imp\" for c in numeric_cols],\n",
        "    strategy=\"median\"\n",
        ")\n",
        "num_imp_cols = [f\"{c}_imp\" for c in numeric_cols]\n",
        "\n",
        "# Indexado y encoding de variables categóricas\n",
        "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid=\"keep\")\n",
        "            for c in categorical_cols]\n",
        "\n",
        "encoder = OneHotEncoder(\n",
        "    inputCols=[f\"{c}_idx\" for c in categorical_cols],\n",
        "    outputCols=[f\"{c}_oh\" for c in categorical_cols]\n",
        ")\n",
        "ohe_cols = [f\"{c}_oh\" for c in categorical_cols]\n",
        "\n",
        "# Assembler y scaler\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=num_imp_cols + ohe_cols,\n",
        "    outputCol=\"features_raw\",\n",
        "    handleInvalid=\"keep\"\n",
        ")\n",
        "\n",
        "scaler = StandardScaler(\n",
        "    inputCol=\"features_raw\",\n",
        "    outputCol=\"features\",\n",
        "    withStd=True,\n",
        "    withMean=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bJo17sbE0UcH",
        "outputId": "467b4839-9cad-4260-cf09-72ecdadd46f9",
        "tags": [
          "remove-input",
          "hide-output"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paso 1: Imputer\n",
            "inputCol: input column name. (undefined)\n",
            "inputCols: input column names. (current: ['monto_aprobado', 'tasa_interes', 'plazo_meses', 'ingreso_anual', 'antiguedad_laboral', 'estado_verif_ingreso', 'promedio_fico', 'anio_apertura_credito', 'cuentas_hipotecarias', 'total_cuentas_credito', 'cuentas_tarjeta_credito', 'saldo_revolvente', 'uso_credito_revolvente', 'limite_credito_total', 'dti', 'meses_ultima_consulta', 'meses_tarjeta_nueva', 'lineas_credito_12m', 'porcentaje_sin_moras', 'moras_2_year', 'monto_total_cobranzas', 'tuvo_acuerdo_pago', 'subcategoria_credito', 'anio_emision_prestamo', 'mes_emision_prestamo'])\n",
            "missingValue: The placeholder for the missing values. All occurrences of missingValue will be imputed. (default: nan)\n",
            "outputCol: output column name. (default: Imputer_78adc9146dfc__output)\n",
            "outputCols: output column names. (current: ['monto_aprobado_imp', 'tasa_interes_imp', 'plazo_meses_imp', 'ingreso_anual_imp', 'antiguedad_laboral_imp', 'estado_verif_ingreso_imp', 'promedio_fico_imp', 'anio_apertura_credito_imp', 'cuentas_hipotecarias_imp', 'total_cuentas_credito_imp', 'cuentas_tarjeta_credito_imp', 'saldo_revolvente_imp', 'uso_credito_revolvente_imp', 'limite_credito_total_imp', 'dti_imp', 'meses_ultima_consulta_imp', 'meses_tarjeta_nueva_imp', 'lineas_credito_12m_imp', 'porcentaje_sin_moras_imp', 'moras_2_year_imp', 'monto_total_cobranzas_imp', 'tuvo_acuerdo_pago_imp', 'subcategoria_credito_imp', 'anio_emision_prestamo_imp', 'mes_emision_prestamo_imp'])\n",
            "relativeError: the relative target precision for the approximate quantile algorithm. Must be in the range [0, 1] (default: 0.001)\n",
            "strategy: strategy for imputation. If mean, then replace missing values using the mean value of the feature. If median, then replace missing values using the median value of the feature. If mode, then replace missing using the most frequent value of the feature. (default: mean, current: median)\n",
            "--------------------------------------------------\n",
            "Paso 2: StringIndexer\n",
            "handleInvalid: how to handle invalid data (unseen or NULL values) in features and label column of string type. Options are 'skip' (filter out rows with invalid data), error (throw an error), or 'keep' (put invalid data in a special additional bucket, at index numLabels). (default: error, current: keep)\n",
            "inputCol: input column name. (current: motivo_prestamo)\n",
            "inputCols: input column names. (undefined)\n",
            "outputCol: output column name. (default: StringIndexer_86a0018c1a2f__output, current: motivo_prestamo_idx)\n",
            "outputCols: output column names. (undefined)\n",
            "stringOrderType: How to order labels of string column. The first label after ordering is assigned an index of 0. Supported options: frequencyDesc, frequencyAsc, alphabetDesc, alphabetAsc. Default is frequencyDesc. In case of equal frequency when under frequencyDesc/Asc, the strings are further sorted alphabetically (default: frequencyDesc)\n",
            "--------------------------------------------------\n",
            "Paso 3: StringIndexer\n",
            "handleInvalid: how to handle invalid data (unseen or NULL values) in features and label column of string type. Options are 'skip' (filter out rows with invalid data), error (throw an error), or 'keep' (put invalid data in a special additional bucket, at index numLabels). (default: error, current: keep)\n",
            "inputCol: input column name. (current: tipo_vivienda)\n",
            "inputCols: input column names. (undefined)\n",
            "outputCol: output column name. (default: StringIndexer_8ae65c497324__output, current: tipo_vivienda_idx)\n",
            "outputCols: output column names. (undefined)\n",
            "stringOrderType: How to order labels of string column. The first label after ordering is assigned an index of 0. Supported options: frequencyDesc, frequencyAsc, alphabetDesc, alphabetAsc. Default is frequencyDesc. In case of equal frequency when under frequencyDesc/Asc, the strings are further sorted alphabetically (default: frequencyDesc)\n",
            "--------------------------------------------------\n",
            "Paso 4: OneHotEncoder\n",
            "dropLast: whether to drop the last category (default: True)\n",
            "handleInvalid: How to handle invalid data during transform(). Options are 'keep' (invalid data presented as an extra categorical feature) or error (throw an error). Note that this Param is only used during transform; during fitting, invalid data will result in an error. (default: error)\n",
            "inputCol: input column name. (undefined)\n",
            "inputCols: input column names. (current: ['motivo_prestamo_idx', 'tipo_vivienda_idx'])\n",
            "outputCol: output column name. (default: OneHotEncoder_fe8b26c07bd7__output)\n",
            "outputCols: output column names. (current: ['motivo_prestamo_oh', 'tipo_vivienda_oh'])\n",
            "--------------------------------------------------\n",
            "Paso 5: VectorAssembler\n",
            "handleInvalid: How to handle invalid data (NULL and NaN values). Options are 'skip' (filter out rows with invalid data), 'error' (throw an error), or 'keep' (return relevant number of NaN in the output). Column lengths are taken from the size of ML Attribute Group, which can be set using `VectorSizeHint` in a pipeline before `VectorAssembler`. Column lengths can also be inferred from first rows of the data since it is safe to do so but only in case of 'error' or 'skip'). (default: error, current: keep)\n",
            "inputCols: input column names. (current: ['monto_aprobado_imp', 'tasa_interes_imp', 'plazo_meses_imp', 'ingreso_anual_imp', 'antiguedad_laboral_imp', 'estado_verif_ingreso_imp', 'promedio_fico_imp', 'anio_apertura_credito_imp', 'cuentas_hipotecarias_imp', 'total_cuentas_credito_imp', 'cuentas_tarjeta_credito_imp', 'saldo_revolvente_imp', 'uso_credito_revolvente_imp', 'limite_credito_total_imp', 'dti_imp', 'meses_ultima_consulta_imp', 'meses_tarjeta_nueva_imp', 'lineas_credito_12m_imp', 'porcentaje_sin_moras_imp', 'moras_2_year_imp', 'monto_total_cobranzas_imp', 'tuvo_acuerdo_pago_imp', 'subcategoria_credito_imp', 'anio_emision_prestamo_imp', 'mes_emision_prestamo_imp', 'motivo_prestamo_oh', 'tipo_vivienda_oh'])\n",
            "outputCol: output column name. (default: VectorAssembler_7e60c6b7bbaa__output, current: features_raw)\n",
            "--------------------------------------------------\n",
            "Paso 6: StandardScaler\n",
            "inputCol: input column name. (current: features_raw)\n",
            "outputCol: output column name. (default: StandardScaler_d2bc1e77e881__output, current: features)\n",
            "withMean: Center data with mean (default: False, current: True)\n",
            "withStd: Scale to unit standard deviation (default: True, current: True)\n",
            "--------------------------------------------------\n",
            "Ajustando pipeline de preprocesamiento...\n",
            "[INFO] Dimensión de entrada = 45\n"
          ]
        }
      ],
      "source": [
        "# 🔹 Pipeline de preprocesamiento\n",
        "preprocessing_stages = [imputer] + indexers + [encoder, assembler, scaler]\n",
        "preprocessing_pipeline = Pipeline(stages=preprocessing_stages)\n",
        "\n",
        "for i, stage in enumerate(preprocessing_pipeline.getStages()):\n",
        "    print(f\"Paso {i+1}: {stage.__class__.__name__}\")\n",
        "    print(stage.explainParams())\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Ajustar el pipeline de preprocesamiento\n",
        "print(\"Ajustando pipeline de preprocesamiento...\")\n",
        "preprocessing_model = preprocessing_pipeline.fit(df)\n",
        "\n",
        "# Transformar todos los datos\n",
        "df_transformed = preprocessing_model.transform(df)\n",
        "\n",
        "# Obtener dimensión de entrada\n",
        "sample_vec = (df_transformed.limit(1)\n",
        "              .select(F.col(\"features\").alias(\"sample_features\"))\n",
        "              .head()[\"sample_features\"])\n",
        "input_dim = sample_vec.size\n",
        "print(f\"[INFO] Dimensión de entrada = {input_dim}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MA13EVC0ZT_",
        "outputId": "0813be90-9865-41f9-ab43-9d7ac4a03776",
        "tags": [
          "remove-input"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 107284\n",
            "Test size: 26948\n",
            "Proporción de clases en train:\n",
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0|85757|\n",
            "|  1.0|21527|\n",
            "+-----+-----+\n",
            "\n",
            "Proporción de clases en test:\n",
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0|21573|\n",
            "|  1.0| 5375|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 🔹 Split train-test\n",
        "train_df, test_df = df_transformed.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(f\"Train size: {train_df.count()}\")\n",
        "print(f\"Test size: {test_df.count()}\")\n",
        "print(\"Proporción de clases en train:\")\n",
        "train_df.groupBy('label').count().show()\n",
        "print(\"Proporción de clases en test:\")\n",
        "test_df.groupBy('label').count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Definición del modelo e hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jli8HbWL0bdj"
      },
      "outputs": [],
      "source": [
        "# 🔹 Configurar MLP con Grid Search\n",
        "mlp = MultilayerPerceptronClassifier(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"label\",\n",
        "    predictionCol=\"prediction\",\n",
        "    rawPredictionCol=\"rawPrediction\",\n",
        "    maxIter=100,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Definir arquitecturas de red\n",
        "layers_options = [\n",
        "    [input_dim, 10, 2],           # Simple\n",
        "    [input_dim, 50, 2],           # Media\n",
        "    [input_dim, 100, 2],          # Grande\n",
        "]\n",
        "\n",
        "# Definir la malla de parámetros\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(mlp.layers, layers_options) \\\n",
        "    .addGrid(mlp.stepSize, [0.1, 0.01, 0.001])\\\n",
        "    .build()\n",
        "\n",
        "# Configurar evaluador\n",
        "evaluator = BinaryClassificationEvaluator(\n",
        "    labelCol=\"label\",\n",
        "    rawPredictionCol=\"rawPrediction\",\n",
        "    metricName=\"areaUnderPR\"  # Usamos PR por desbalance de datos\n",
        ")\n",
        "\n",
        "# Configurar CrossValidator\n",
        "crossval = CrossValidator(\n",
        "    estimator=mlp,\n",
        "    estimatorParamMaps=paramGrid,\n",
        "    evaluator=evaluator,\n",
        "    numFolds=3,\n",
        "    seed=42,\n",
        "    collectSubModels=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cKeeohz0dbe",
        "outputId": "8a6e07c0-0da9-4cac-fc33-2ca34f1ebf7f",
        "tags": [
          "remove-input"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando grid search...\n",
            "Tiempo de entrenamiento: 3738.77 segundos\n"
          ]
        }
      ],
      "source": [
        "# 🔹 Entrenar el modelo\n",
        "print(\"Iniciando grid search...\")\n",
        "start_time = time.time()\n",
        "\n",
        "cv_model = crossval.fit(train_df)\n",
        "\n",
        "fit_time = time.time() - start_time\n",
        "print(f\"Tiempo de entrenamiento: {fit_time:.2f} segundos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGhCx_FjFFij",
        "outputId": "ea3459f3-78cf-4c49-e29a-9598ec447272",
        "tags": [
          "remove-input"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "══════════════════════════════════════════════════\n",
            "MEJORES PARÁMETROS ENCONTRADOS\n",
            "══════════════════════════════════════════════════\n",
            "layers         : [45, 10, 2]\n",
            "stepSize       : 0.1\n",
            "maxIter        : 100\n",
            "blockSize      : 128\n",
            "solver         : l-bfgs\n",
            "\n",
            "══════════════════════════════════════════════════\n",
            "OTROS PARÁMETROS\n",
            "══════════════════════════════════════════════════\n",
            "featuresCol    : features\n",
            "labelCol       : label\n",
            "predictionCol  : prediction\n",
            "probabilityCol : probability\n",
            "rawPredictionCol: rawPrediction\n",
            "seed           : 42\n",
            "tol            : 1e-06\n"
          ]
        }
      ],
      "source": [
        "# Visualizar los parámetros\n",
        "best_params = cv_model.bestModel.extractParamMap()\n",
        "\n",
        "print(\"═\" * 50)\n",
        "print(\"MEJORES PARÁMETROS ENCONTRADOS\")\n",
        "print(\"═\" * 50)\n",
        "\n",
        "# Parámetros más importantes primero\n",
        "important_params = ['layers', 'stepSize', 'maxIter', 'blockSize', 'solver']\n",
        "for param_name in important_params:\n",
        "    for param_obj, value in best_params.items():\n",
        "        if param_obj.name == param_name:\n",
        "            print(f\"{param_name:15}: {value}\")\n",
        "            break\n",
        "\n",
        "print(\"\\n\" + \"═\" * 50)\n",
        "print(\"OTROS PARÁMETROS\")\n",
        "print(\"═\" * 50)\n",
        "\n",
        "# El resto de parámetros\n",
        "for param_obj, value in best_params.items():\n",
        "    if param_obj.name not in important_params:\n",
        "        print(f\"{param_obj.name:15}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUnb8dZqDVja",
        "outputId": "8640ed33-2045-4a2e-d6ff-32fc38acb11b",
        "tags": [
          "remove-input"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluando modelo con métricas\n",
            "\n",
            "════════════════════════════════════════════════════════════════════════════════\n",
            "RENDIMIENTO DEL MEJOR MODELO - MÉTRICAS COMPLETAS\n",
            "════════════════════════════════════════════════════════════════════════════════\n",
            "Métrica         Train      Test       Diferencia  \n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "AUC_ROC         0.7504    0.7389    0.0115\n",
            "AUC_PR          0.5129    0.4935    0.0195\n",
            "F1              0.7834    0.7804    0.0030\n",
            "Precision       0.8194    0.8123    0.0071\n",
            "Recall          0.8274    0.8251    0.0023\n",
            "Accuracy        0.8274    0.8251    0.0023\n",
            "════════════════════════════════════════════════════════════════════════════════\n"
          ]
        }
      ],
      "source": [
        "# 7. Evaluar el mejor modelo COMPLETAMENTE\n",
        "print(\"Evaluando modelo con métricas\")\n",
        "best_model = cv_model.bestModel\n",
        "\n",
        "# Evaluación comprehensiva\n",
        "results = evaluate_model_comprehensive(best_model, train_df, test_df)\n",
        "\n",
        "# Mostrar resultados en formato tabular\n",
        "print(\"\\n\" + \"═\" * 80)\n",
        "print(\"RENDIMIENTO DEL MEJOR MODELO - MÉTRICAS COMPLETAS\")\n",
        "print(\"═\" * 80)\n",
        "print(f\"{'Métrica':<15} {'Train':<10} {'Test':<10} {'Diferencia':<12}\")\n",
        "print(\"─\" * 80)\n",
        "\n",
        "metrics_to_display = ['AUC_ROC', 'AUC_PR', 'F1', 'Precision', 'Recall', 'Accuracy']\n",
        "\n",
        "for metric in metrics_to_display:\n",
        "    train_val = results['train_metrics'][metric]\n",
        "    test_val = results['test_metrics'][metric]\n",
        "    difference = abs(train_val - test_val)\n",
        "\n",
        "    print(f\"{metric:<15} {train_val:.4f}    {test_val:.4f}    {difference:.4f}\")\n",
        "\n",
        "print(\"═\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2AkQPwIDZfp",
        "outputId": "89d59253-1267-48bf-df39-5bb2125ba321",
        "tags": [
          "remove-input"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MATRIZ DE CONFUSIÓN\n",
            "════════════════════════════════════════\n",
            "Actual \\ Predicted |  0  |  1  |\n",
            "-------------------|-----|-----|\n",
            "        0          |21224| 349 |\n",
            "-------------------|-----|-----|\n",
            "        1          |4364 |1011 |\n",
            "-------------------|-----|-----|\n"
          ]
        }
      ],
      "source": [
        "test_predictions = best_model.transform(test_df)\n",
        "def get_confusion_matrix_robust(predictions, labelCol=\"label\", predictionCol=\"prediction\"):\n",
        "    \"\"\"Versión robusta para obtener matriz de confusión\"\"\"\n",
        "\n",
        "    # Calcular conteos\n",
        "    confusion_counts = predictions.groupBy(\n",
        "        F.col(labelCol).alias(\"actual\"),\n",
        "        F.col(predictionCol).alias(\"predicted\")\n",
        "    ).count()\n",
        "\n",
        "    # Colectar datos de forma segura\n",
        "    confusion_data = []\n",
        "    for row in confusion_counts.collect():\n",
        "        confusion_data.append({\n",
        "            'actual': row['actual'],\n",
        "            'predicted': row['predicted'],\n",
        "            'count': row['count']\n",
        "        })\n",
        "\n",
        "    # Crear matriz 2x2\n",
        "    matrix = {\n",
        "        (0.0, 0.0): 0, (0.0, 1.0): 0,\n",
        "        (1.0, 0.0): 0, (1.0, 1.0): 0\n",
        "    }\n",
        "\n",
        "    for item in confusion_data:\n",
        "        matrix[(item['actual'], item['predicted'])] = item['count']\n",
        "\n",
        "    return matrix\n",
        "\n",
        "# Usar la función robusta\n",
        "confusion_matrix = get_confusion_matrix_robust(test_predictions)\n",
        "\n",
        "print(\"MATRIZ DE CONFUSIÓN\")\n",
        "print(\"═\" * 40)\n",
        "print(\"Actual \\\\ Predicted |  0  |  1  |\")\n",
        "print(\"-------------------|-----|-----|\")\n",
        "print(f\"        0          |{confusion_matrix[(0.0, 0.0)]:4d}|{confusion_matrix[(0.0, 1.0)]:4d} |\")\n",
        "print(\"-------------------|-----|-----|\")\n",
        "print(f\"        1          |{confusion_matrix[(1.0, 0.0)]:4d} |{confusion_matrix[(1.0, 1.0)]:4d} |\")\n",
        "print(\"-------------------|-----|-----|\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1JyV7-lDcaF",
        "outputId": "0aff82e4-8d64-4344-c2dc-0cf0ee18365c",
        "tags": [
          "remove-input"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MÉTRICAS CALCULADAS DIRECTAMENTE DESDE SPARK:\n",
            " class_0: Precision=0.8295, Recall=0.9838, F1=0.9001\n",
            " class_1: Precision=0.7434, Recall=0.1881, F1=0.3002\n",
            "\n",
            " Matriz de Confusión:\n",
            "True Negatives (TN):  21224\n",
            "False Positives (FP): 349\n",
            "False Negatives (FN): 4364\n",
            "True Positives (TP):  1011\n"
          ]
        }
      ],
      "source": [
        "def calculate_metrics_from_spark(test_predictions, labelCol=\"label\", predictionCol=\"prediction\"):\n",
        "    \"\"\"Calcular métricas directamente desde DataFrame de Spark\"\"\"\n",
        "\n",
        "    # Calcular matriz de confusión manualmente\n",
        "    confusion_data = test_predictions.groupBy(\n",
        "        F.col(labelCol).alias(\"Actual\"),\n",
        "        F.col(predictionCol).alias(\"Predicted\")\n",
        "    ).count().collect()\n",
        "\n",
        "    # Inicializar contadores\n",
        "    tn, fp, fn, tp = 0, 0, 0, 0\n",
        "\n",
        "    for row in confusion_data:\n",
        "        if row['Actual'] == 0.0 and row['Predicted'] == 0.0:\n",
        "            tn = row['count']\n",
        "        elif row['Actual'] == 0.0 and row['Predicted'] == 1.0:\n",
        "            fp = row['count']\n",
        "        elif row['Actual'] == 1.0 and row['Predicted'] == 0.0:\n",
        "            fn = row['count']\n",
        "        elif row['Actual'] == 1.0 and row['Predicted'] == 1.0:\n",
        "            tp = row['count']\n",
        "\n",
        "    # Calcular métricas\n",
        "    precision_0 = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
        "    recall_0 = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    f1_0 = 2 * (precision_0 * recall_0) / (precision_0 + recall_0) if (precision_0 + recall_0) > 0 else 0\n",
        "\n",
        "    precision_1 = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall_1 = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1_1 = 2 * (precision_1 * recall_1) / (precision_1 + recall_1) if (precision_1 + recall_1) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'class_0': {'precision': precision_0, 'recall': recall_0, 'f1': f1_0},\n",
        "        'class_1': {'precision': precision_1, 'recall': recall_1, 'f1': f1_1},\n",
        "        'confusion_matrix': {'TN': tn, 'FP': fp, 'FN': fn, 'TP': tp}\n",
        "    }\n",
        "\n",
        "# Usar esta versión alternativa\n",
        "spark_metrics = calculate_metrics_from_spark(test_predictions)\n",
        "\n",
        "print(\"MÉTRICAS CALCULADAS DIRECTAMENTE DESDE SPARK:\")\n",
        "for class_name, metrics in spark_metrics.items():\n",
        "    if class_name != 'confusion_matrix':\n",
        "        print(f\" {class_name}: Precision={metrics['precision']:.4f}, Recall={metrics['recall']:.4f}, F1={metrics['f1']:.4f}\")\n",
        "\n",
        "# Mostrar matriz de confusión también\n",
        "print(f\"\\n Matriz de Confusión:\")\n",
        "print(f\"True Negatives (TN):  {spark_metrics['confusion_matrix']['TN']}\")\n",
        "print(f\"False Positives (FP): {spark_metrics['confusion_matrix']['FP']}\")\n",
        "print(f\"False Negatives (FN): {spark_metrics['confusion_matrix']['FN']}\")\n",
        "print(f\"True Positives (TP):  {spark_metrics['confusion_matrix']['TP']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laQN7u3_Dvx2",
        "outputId": "60e5a77a-2132-4a93-eef9-fab60b0c7e6a",
        "tags": [
          "remove-input"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " ANÁLISIS DE OVERFITTING:\n",
            "✅ AUC_ROC: Buen generalización (Diff = 0.0115)\n",
            "✅ AUC_PR: Buen generalización (Diff = 0.0195)\n",
            "✅ F1: Buen generalización (Diff = 0.0030)\n",
            "✅ Precision: Buen generalización (Diff = 0.0071)\n",
            "✅ Recall: Buen generalización (Diff = 0.0023)\n",
            "✅ Accuracy: Buen generalización (Diff = 0.0023)\n"
          ]
        }
      ],
      "source": [
        "# Análisis de overfitting\n",
        "print(\"\\n ANÁLISIS DE OVERFITTING:\")\n",
        "overfitting_threshold = 0.05  # Diferencia máxima aceptable\n",
        "\n",
        "for metric in metrics_to_display:\n",
        "    train_val = results['train_metrics'][metric]\n",
        "    test_val = results['test_metrics'][metric]\n",
        "    difference = abs(train_val - test_val)\n",
        "\n",
        "    if difference > overfitting_threshold:\n",
        "        print(f\" Posible overfitting en {metric}: Diff = {difference:.4f}\")\n",
        "    else:\n",
        "        print(f\"✅ {metric}: Buen generalización (Diff = {difference:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los resultados del grid search indican que se ha encontrado un modelo con buen rendimiento y excelente capacidad de generalización. La estructura de red neuronal [45, 10, 2] con el optimizador L-BFGS y parámetros específicos (stepSize: 0.1, maxIter: 100) logra un equilibrio óptimo entre aprendizaje y generalización, como evidencia la mínima diferencia entre las métricas de entrenamiento y prueba (todas por debajo del 2%). \n",
        "\n",
        "El AUC-ROC de 0.7389 en test demuestra una capacidad aceptable de discriminación entre clases, mientras que el accuracy del 82.51% refleja una precisión general sólida del modelo.\n",
        "\n",
        "Sin embargo, el análisis detallado revela un desbalance significativo en el rendimiento por clases. Mientras la clase 0 muestra excelentes métricas (Precision: 0.8295, Recall: 0.9838), la clase 1 presenta un recall muy bajo (0.1881), indicando que el modelo identifica correctamente solo el 18.81% de los casos positivos reales. \n",
        "\n",
        "Esta disparidad, evidente en la matriz de confusión con 4364 falsos negativos frente a solo 1011 verdaderos positivos, sugiere que el modelo tiene tendencia a predecir la clase mayoritaria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6hS15Nu0Rri"
      },
      "source": [
        "__________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WhkF7ec69L6"
      },
      "source": [
        "## MLP con los mejores hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Uso de todos los registros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpo2JKeK7JqZ"
      },
      "outputs": [],
      "source": [
        "# 🔹 Lectura de datos [100% de los registros]\n",
        "full_data = spark.read.csv(\"data_to_model.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SuTr7yO7bkm",
        "outputId": "3420afcc-a4cf-481c-8cf1-de70b93c879f",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variables categóricas: ['motivo_prestamo', 'tipo_vivienda']\n",
            "Variables numéricas: ['monto_aprobado', 'tasa_interes', 'plazo_meses', 'ingreso_anual', 'antiguedad_laboral', 'estado_verif_ingreso', 'promedio_fico', 'anio_apertura_credito', 'cuentas_hipotecarias', 'total_cuentas_credito', 'cuentas_tarjeta_credito', 'saldo_revolvente', 'uso_credito_revolvente', 'limite_credito_total', 'dti', 'meses_ultima_consulta', 'meses_tarjeta_nueva', 'lineas_credito_12m', 'porcentaje_sin_moras', 'moras_2_year', 'monto_total_cobranzas', 'tuvo_acuerdo_pago', 'subcategoria_credito', 'anio_emision_prestamo', 'mes_emision_prestamo']\n"
          ]
        }
      ],
      "source": [
        "# 🔹 Configuración inicial\n",
        "\n",
        "# Variable objetivo\n",
        "label_col = \"default\"\n",
        "\n",
        "# Detección automática de columnas\n",
        "categorical_cols = [\n",
        "    col for col in full_data.columns\n",
        "    if full_data.schema[col].dataType.typeName() == 'string' and col != label_col]\n",
        "numeric_cols = [\n",
        "    col for col in full_data.columns\n",
        "    if full_data.schema[col].dataType.typeName() in ['integer', 'double', 'float'] and col != label_col]\n",
        "\n",
        "print(f\"Variables categóricas: {categorical_cols}\")\n",
        "print(f\"Variables numéricas: {numeric_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuLqdPDu72AD",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# 🔹 Preprocesamiento\n",
        "\n",
        "# Convertir label a DoubleType y filtrar nulos\n",
        "full_data = full_data.withColumn(\"label\", F.col(label_col).cast(DoubleType()))\\\n",
        "       .filter(F.col(\"label\").isNotNull())\n",
        "\n",
        "# Imputación de valores nulos en variables numéricas\n",
        "imputer = Imputer(\n",
        "    inputCols=numeric_cols,\n",
        "    outputCols=[f\"{c}_imp\" for c in numeric_cols],\n",
        "    strategy=\"median\"\n",
        ")\n",
        "num_imp_cols = [f\"{c}_imp\" for c in numeric_cols]\n",
        "\n",
        "# Indexado y encoding de variables categóricas\n",
        "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid=\"keep\")\n",
        "            for c in categorical_cols]\n",
        "\n",
        "encoder = OneHotEncoder(\n",
        "    inputCols=[f\"{c}_idx\" for c in categorical_cols],\n",
        "    outputCols=[f\"{c}_oh\" for c in categorical_cols]\n",
        ")\n",
        "ohe_cols = [f\"{c}_oh\" for c in categorical_cols]\n",
        "\n",
        "# Assembler y scaler\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=num_imp_cols + ohe_cols,\n",
        "    outputCol=\"features_raw\",\n",
        "    handleInvalid=\"keep\"\n",
        ")\n",
        "\n",
        "scaler = StandardScaler(\n",
        "    inputCol=\"features_raw\",\n",
        "    outputCol=\"features\",\n",
        "    withStd=True,\n",
        "    withMean=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtI0-Ozh9IV7",
        "outputId": "25071bc0-9248-46af-9317-49308077fb9f",
        "tags": [
          "remove-input",
          "hide-output"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paso 1: Imputer\n",
            "inputCol: input column name. (undefined)\n",
            "inputCols: input column names. (current: ['monto_aprobado', 'tasa_interes', 'plazo_meses', 'ingreso_anual', 'antiguedad_laboral', 'estado_verif_ingreso', 'promedio_fico', 'anio_apertura_credito', 'cuentas_hipotecarias', 'total_cuentas_credito', 'cuentas_tarjeta_credito', 'saldo_revolvente', 'uso_credito_revolvente', 'limite_credito_total', 'dti', 'meses_ultima_consulta', 'meses_tarjeta_nueva', 'lineas_credito_12m', 'porcentaje_sin_moras', 'moras_2_year', 'monto_total_cobranzas', 'tuvo_acuerdo_pago', 'subcategoria_credito', 'anio_emision_prestamo', 'mes_emision_prestamo'])\n",
            "missingValue: The placeholder for the missing values. All occurrences of missingValue will be imputed. (default: nan)\n",
            "outputCol: output column name. (default: Imputer_b4c2aa4cccf0__output)\n",
            "outputCols: output column names. (current: ['monto_aprobado_imp', 'tasa_interes_imp', 'plazo_meses_imp', 'ingreso_anual_imp', 'antiguedad_laboral_imp', 'estado_verif_ingreso_imp', 'promedio_fico_imp', 'anio_apertura_credito_imp', 'cuentas_hipotecarias_imp', 'total_cuentas_credito_imp', 'cuentas_tarjeta_credito_imp', 'saldo_revolvente_imp', 'uso_credito_revolvente_imp', 'limite_credito_total_imp', 'dti_imp', 'meses_ultima_consulta_imp', 'meses_tarjeta_nueva_imp', 'lineas_credito_12m_imp', 'porcentaje_sin_moras_imp', 'moras_2_year_imp', 'monto_total_cobranzas_imp', 'tuvo_acuerdo_pago_imp', 'subcategoria_credito_imp', 'anio_emision_prestamo_imp', 'mes_emision_prestamo_imp'])\n",
            "relativeError: the relative target precision for the approximate quantile algorithm. Must be in the range [0, 1] (default: 0.001)\n",
            "strategy: strategy for imputation. If mean, then replace missing values using the mean value of the feature. If median, then replace missing values using the median value of the feature. If mode, then replace missing using the most frequent value of the feature. (default: mean, current: median)\n",
            "--------------------------------------------------\n",
            "Paso 2: StringIndexer\n",
            "handleInvalid: how to handle invalid data (unseen or NULL values) in features and label column of string type. Options are 'skip' (filter out rows with invalid data), error (throw an error), or 'keep' (put invalid data in a special additional bucket, at index numLabels). (default: error, current: keep)\n",
            "inputCol: input column name. (current: motivo_prestamo)\n",
            "inputCols: input column names. (undefined)\n",
            "outputCol: output column name. (default: StringIndexer_dac6857c81bf__output, current: motivo_prestamo_idx)\n",
            "outputCols: output column names. (undefined)\n",
            "stringOrderType: How to order labels of string column. The first label after ordering is assigned an index of 0. Supported options: frequencyDesc, frequencyAsc, alphabetDesc, alphabetAsc. Default is frequencyDesc. In case of equal frequency when under frequencyDesc/Asc, the strings are further sorted alphabetically (default: frequencyDesc)\n",
            "--------------------------------------------------\n",
            "Paso 3: StringIndexer\n",
            "handleInvalid: how to handle invalid data (unseen or NULL values) in features and label column of string type. Options are 'skip' (filter out rows with invalid data), error (throw an error), or 'keep' (put invalid data in a special additional bucket, at index numLabels). (default: error, current: keep)\n",
            "inputCol: input column name. (current: tipo_vivienda)\n",
            "inputCols: input column names. (undefined)\n",
            "outputCol: output column name. (default: StringIndexer_8ebb3279606d__output, current: tipo_vivienda_idx)\n",
            "outputCols: output column names. (undefined)\n",
            "stringOrderType: How to order labels of string column. The first label after ordering is assigned an index of 0. Supported options: frequencyDesc, frequencyAsc, alphabetDesc, alphabetAsc. Default is frequencyDesc. In case of equal frequency when under frequencyDesc/Asc, the strings are further sorted alphabetically (default: frequencyDesc)\n",
            "--------------------------------------------------\n",
            "Paso 4: OneHotEncoder\n",
            "dropLast: whether to drop the last category (default: True)\n",
            "handleInvalid: How to handle invalid data during transform(). Options are 'keep' (invalid data presented as an extra categorical feature) or error (throw an error). Note that this Param is only used during transform; during fitting, invalid data will result in an error. (default: error)\n",
            "inputCol: input column name. (undefined)\n",
            "inputCols: input column names. (current: ['motivo_prestamo_idx', 'tipo_vivienda_idx'])\n",
            "outputCol: output column name. (default: OneHotEncoder_86f37fb340dd__output)\n",
            "outputCols: output column names. (current: ['motivo_prestamo_oh', 'tipo_vivienda_oh'])\n",
            "--------------------------------------------------\n",
            "Paso 5: VectorAssembler\n",
            "handleInvalid: How to handle invalid data (NULL and NaN values). Options are 'skip' (filter out rows with invalid data), 'error' (throw an error), or 'keep' (return relevant number of NaN in the output). Column lengths are taken from the size of ML Attribute Group, which can be set using `VectorSizeHint` in a pipeline before `VectorAssembler`. Column lengths can also be inferred from first rows of the data since it is safe to do so but only in case of 'error' or 'skip'). (default: error, current: keep)\n",
            "inputCols: input column names. (current: ['monto_aprobado_imp', 'tasa_interes_imp', 'plazo_meses_imp', 'ingreso_anual_imp', 'antiguedad_laboral_imp', 'estado_verif_ingreso_imp', 'promedio_fico_imp', 'anio_apertura_credito_imp', 'cuentas_hipotecarias_imp', 'total_cuentas_credito_imp', 'cuentas_tarjeta_credito_imp', 'saldo_revolvente_imp', 'uso_credito_revolvente_imp', 'limite_credito_total_imp', 'dti_imp', 'meses_ultima_consulta_imp', 'meses_tarjeta_nueva_imp', 'lineas_credito_12m_imp', 'porcentaje_sin_moras_imp', 'moras_2_year_imp', 'monto_total_cobranzas_imp', 'tuvo_acuerdo_pago_imp', 'subcategoria_credito_imp', 'anio_emision_prestamo_imp', 'mes_emision_prestamo_imp', 'motivo_prestamo_oh', 'tipo_vivienda_oh'])\n",
            "outputCol: output column name. (default: VectorAssembler_230d91db8e0a__output, current: features_raw)\n",
            "--------------------------------------------------\n",
            "Paso 6: StandardScaler\n",
            "inputCol: input column name. (current: features_raw)\n",
            "outputCol: output column name. (default: StandardScaler_8399a487e431__output, current: features)\n",
            "withMean: Center data with mean (default: False, current: True)\n",
            "withStd: Scale to unit standard deviation (default: True, current: True)\n",
            "--------------------------------------------------\n",
            "Ajustando pipeline de preprocesamiento...\n",
            "Dimensión de entrada = 45\n"
          ]
        }
      ],
      "source": [
        "# 🔹 Pipeline de preprocesamiento\n",
        "preprocessing_stages = [imputer] + indexers + [encoder, assembler, scaler]\n",
        "preprocessing_pipeline = Pipeline(stages=preprocessing_stages)\n",
        "\n",
        "for i, stage in enumerate(preprocessing_pipeline.getStages()):\n",
        "    print(f\"Paso {i+1}: {stage.__class__.__name__}\")\n",
        "    print(stage.explainParams())\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Ajustar el pipeline de preprocesamiento\n",
        "print(\"Ajustando pipeline de preprocesamiento...\")\n",
        "preprocessing_model = preprocessing_pipeline.fit(full_data)\n",
        "\n",
        "# Transformar todos los datos\n",
        "full_data_transformed = preprocessing_model.transform(full_data)\n",
        "\n",
        "# Obtener dimensión de entrada\n",
        "sample_vec = (df_transformed.limit(1)\n",
        "              .select(F.col(\"features\").alias(\"sample_features\"))\n",
        "              .head()[\"sample_features\"])\n",
        "input_dim = sample_vec.size\n",
        "print(f\"Dimensión de entrada = {input_dim}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DGIIbLu9YKh",
        "outputId": "737b1ec1-b457-44d9-cbc9-bc85eaea8618",
        "tags": [
          "remove-input"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 1076425\n",
            "Test size: 268885\n",
            "Proporción de clases en train:\n",
            "+-----+------+\n",
            "|label| count|\n",
            "+-----+------+\n",
            "|  0.0|861332|\n",
            "|  1.0|215093|\n",
            "+-----+------+\n",
            "\n",
            "Proporción de clases en test:\n",
            "+-----+------+\n",
            "|label| count|\n",
            "+-----+------+\n",
            "|  0.0|215419|\n",
            "|  1.0| 53466|\n",
            "+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 🔹 Split train-test\n",
        "train_data, test_data = full_data_transformed.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(f\"Train size: {train_data.count()}\")\n",
        "print(f\"Test size: {test_data.count()}\")\n",
        "print(\"Proporción de clases en train:\")\n",
        "train_data.groupBy('label').count().show()\n",
        "print(\"Proporción de clases en test:\")\n",
        "test_data.groupBy('label').count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* **Modelo MLP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "hQhBia9R32Zr"
      },
      "outputs": [],
      "source": [
        "# 🔹 Configurar modelo con los mejores hiperparámetros\n",
        "final_mlp = MultilayerPerceptronClassifier(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"label\",\n",
        "    predictionCol=\"prediction\",\n",
        "    rawPredictionCol=\"rawPrediction\",\n",
        "    layers=[45, 10, 2],      # Mejores parámetros\n",
        "    stepSize=0.01,           # Learning rate óptimo\n",
        "    maxIter=100,\n",
        "    blockSize=128,           # Block size para más datos\n",
        "    solver=\"l-bfgs\",         # Algoritmo eficiente\n",
        "    tol=1e-06,\n",
        "    seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiX8P-cj1pEV",
        "outputId": "3cf28dde-0a88-4e42-a770-700af4f09471",
        "tags": [
          "remove-input"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando modelo final-----\n",
            "Entrenamiento completado en 5.36 minutos\n"
          ]
        }
      ],
      "source": [
        "# 🔹 Entrenar modelo final\n",
        "print(\"Entrenando modelo final-----\")\n",
        "start_time = time.time()\n",
        "\n",
        "final_model = final_mlp.fit(train_data)\n",
        "\n",
        "training_time = (time.time() - start_time) / 60\n",
        "print(f\"Entrenamiento completado en {training_time:.2f} minutos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKnVHNFKHYg3",
        "outputId": "e81728c4-d625-48d6-bdfc-bf93e315422d",
        "tags": [
          "remove-input"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluando modelo final con métricas\n",
            "Tiempo de evaluación: 0.00 minutos\n",
            "\n",
            "════════════════════════════════════════════════════════════════════════════════\n",
            "RENDIMIENTO DEL MEJOR MODELO - MÉTRICAS COMPLETAS\n",
            "════════════════════════════════════════════════════════════════════════════════\n",
            "Métrica         Train      Test       Diferencia  \n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "AUC_ROC         0.7426    0.7440    0.0014\n",
            "AUC_PR          0.5004    0.5026    0.0022\n",
            "F1              0.7808    0.7829    0.0020\n",
            "Precision       0.8232    0.8243    0.0011\n",
            "Recall          0.8275    0.8288    0.0013\n",
            "Accuracy        0.8275    0.8288    0.0013\n",
            "════════════════════════════════════════════════════════════════════════════════\n"
          ]
        }
      ],
      "source": [
        "# 🔹 Evaluar el modelo\n",
        "\n",
        "print(\"Evaluando modelo final con métricas\")\n",
        "start_time = time.time()\n",
        "test_predictions = final_model.transform(test_data)\n",
        "fit_time = (time.time() - start_time)/60\n",
        "print(f\"Tiempo de evaluación: {fit_time:.2f} minutos\")\n",
        "\n",
        "# Evaluación comprehensiva\n",
        "results = evaluate_model_comprehensive(final_model, train_data, test_data)\n",
        "\n",
        "# Mostrar resultados en formato tabular\n",
        "print(\"\\n\" + \"═\" * 80)\n",
        "print(\"RENDIMIENTO DEL MEJOR MODELO - MÉTRICAS COMPLETAS\")\n",
        "print(\"═\" * 80)\n",
        "print(f\"{'Métrica':<15} {'Train':<10} {'Test':<10} {'Diferencia':<12}\")\n",
        "print(\"─\" * 80)\n",
        "\n",
        "metrics_to_display = ['AUC_ROC', 'AUC_PR', 'F1', 'Precision', 'Recall', 'Accuracy']\n",
        "\n",
        "for metric in metrics_to_display:\n",
        "    train_val = results['train_metrics'][metric]\n",
        "    test_val = results['test_metrics'][metric]\n",
        "    difference = abs(train_val - test_val)\n",
        "\n",
        "    print(f\"{metric:<15} {train_val:.4f}    {test_val:.4f}    {difference:.4f}\")\n",
        "\n",
        "print(\"═\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CoP2h8nJ-gH",
        "outputId": "1845f3d5-c5d5-49ba-ad6f-6d89193d6cb2",
        "tags": [
          "remove-input"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MATRIZ DE CONFUSIÓN\n",
            "════════════════════════════════════════\n",
            "Actual \\ Predicted |  0  |  1  |\n",
            "-------------------|------|-----|\n",
            "        0          |212951|2468 |\n",
            "-------------------|------|-----|\n",
            "        1          |43557 |9909 |\n",
            "-------------------|------|-----|\n"
          ]
        }
      ],
      "source": [
        "def get_confusion_matrix_robust(predictions, labelCol=\"label\", predictionCol=\"prediction\"):\n",
        "    \"\"\"Versión robusta para obtener matriz de confusión\"\"\"\n",
        "\n",
        "    # Calcular conteos\n",
        "    confusion_counts = predictions.groupBy(\n",
        "        F.col(labelCol).alias(\"actual\"),\n",
        "        F.col(predictionCol).alias(\"predicted\")\n",
        "    ).count()\n",
        "\n",
        "    # Colectar datos de forma segura\n",
        "    confusion_data = []\n",
        "    for row in confusion_counts.collect():\n",
        "        confusion_data.append({\n",
        "            'actual': row['actual'],\n",
        "            'predicted': row['predicted'],\n",
        "            'count': row['count']\n",
        "        })\n",
        "\n",
        "    # Crear matriz 2x2\n",
        "    matrix = {\n",
        "        (0.0, 0.0): 0, (0.0, 1.0): 0,\n",
        "        (1.0, 0.0): 0, (1.0, 1.0): 0\n",
        "    }\n",
        "\n",
        "    for item in confusion_data:\n",
        "        matrix[(item['actual'], item['predicted'])] = item['count']\n",
        "\n",
        "    return matrix\n",
        "\n",
        "# Usar la función robusta\n",
        "confusion_matrix = get_confusion_matrix_robust(test_predictions)\n",
        "\n",
        "print(\"MATRIZ DE CONFUSIÓN\")\n",
        "print(\"═\" * 40)\n",
        "print(\"Actual \\\\ Predicted |  0  |  1  |\")\n",
        "print(\"-------------------|------|-----|\")\n",
        "print(f\"        0          |{confusion_matrix[(0.0, 0.0)]:4d}|{confusion_matrix[(0.0, 1.0)]:4d} |\")\n",
        "print(\"-------------------|------|-----|\")\n",
        "print(f\"        1          |{confusion_matrix[(1.0, 0.0)]:4d} |{confusion_matrix[(1.0, 1.0)]:4d} |\")\n",
        "print(\"-------------------|------|-----|\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWyRawy-KEwr",
        "outputId": "61766474-0887-47de-930f-6a9be4fd991f",
        "tags": [
          "remove-input"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MÉTRICAS CALCULADAS DIRECTAMENTE DESDE SPARK:\n",
            " class_0: Precision=0.8302, Recall=0.9885, F1=0.9025\n",
            " class_1: Precision=0.8006, Recall=0.1853, F1=0.3010\n",
            "\n",
            " Matriz de Confusión:\n",
            "True Negatives (TN):  212951\n",
            "False Positives (FP): 2468\n",
            "False Negatives (FN): 43557\n",
            "True Positives (TP):  9909\n"
          ]
        }
      ],
      "source": [
        "def calculate_metrics_from_spark(test_predictions, labelCol=\"label\", predictionCol=\"prediction\"):\n",
        "    \"\"\"Calcular métricas directamente desde DataFrame de Spark\"\"\"\n",
        "\n",
        "    # Calcular matriz de confusión manualmente\n",
        "    confusion_data = test_predictions.groupBy(\n",
        "        F.col(labelCol).alias(\"Actual\"),\n",
        "        F.col(predictionCol).alias(\"Predicted\")\n",
        "    ).count().collect()\n",
        "\n",
        "    # Inicializar contadores\n",
        "    tn, fp, fn, tp = 0, 0, 0, 0\n",
        "\n",
        "    for row in confusion_data:\n",
        "        if row['Actual'] == 0.0 and row['Predicted'] == 0.0:\n",
        "            tn = row['count']\n",
        "        elif row['Actual'] == 0.0 and row['Predicted'] == 1.0:\n",
        "            fp = row['count']\n",
        "        elif row['Actual'] == 1.0 and row['Predicted'] == 0.0:\n",
        "            fn = row['count']\n",
        "        elif row['Actual'] == 1.0 and row['Predicted'] == 1.0:\n",
        "            tp = row['count']\n",
        "\n",
        "    # Calcular métricas\n",
        "    precision_0 = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
        "    recall_0 = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    f1_0 = 2 * (precision_0 * recall_0) / (precision_0 + recall_0) if (precision_0 + recall_0) > 0 else 0\n",
        "\n",
        "    precision_1 = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall_1 = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1_1 = 2 * (precision_1 * recall_1) / (precision_1 + recall_1) if (precision_1 + recall_1) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'class_0': {'precision': precision_0, 'recall': recall_0, 'f1': f1_0},\n",
        "        'class_1': {'precision': precision_1, 'recall': recall_1, 'f1': f1_1},\n",
        "        'confusion_matrix': {'TN': tn, 'FP': fp, 'FN': fn, 'TP': tp}\n",
        "    }\n",
        "\n",
        "# Usar esta versión alternativa\n",
        "spark_metrics = calculate_metrics_from_spark(test_predictions)\n",
        "\n",
        "print(\"MÉTRICAS CALCULADAS DIRECTAMENTE DESDE SPARK:\")\n",
        "for class_name, metrics in spark_metrics.items():\n",
        "    if class_name != 'confusion_matrix':\n",
        "        print(f\" {class_name}: Precision={metrics['precision']:.4f}, Recall={metrics['recall']:.4f}, F1={metrics['f1']:.4f}\")\n",
        "\n",
        "# Mostrar matriz de confusión también\n",
        "print(f\"\\n Matriz de Confusión:\")\n",
        "print(f\"True Negatives (TN):  {spark_metrics['confusion_matrix']['TN']}\")\n",
        "print(f\"False Positives (FP): {spark_metrics['confusion_matrix']['FP']}\")\n",
        "print(f\"False Negatives (FN): {spark_metrics['confusion_matrix']['FN']}\")\n",
        "print(f\"True Positives (TP):  {spark_metrics['confusion_matrix']['TP']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMD5HVUwKM24",
        "outputId": "30f3a029-1bda-481e-9184-77f49e249567",
        "tags": [
          "remove-input"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " ANÁLISIS DE OVERFITTING:\n",
            "✅ AUC_ROC: Buen generalización (Diff = 0.0014)\n",
            "✅ AUC_PR: Buen generalización (Diff = 0.0022)\n",
            "✅ F1: Buen generalización (Diff = 0.0020)\n",
            "✅ Precision: Buen generalización (Diff = 0.0011)\n",
            "✅ Recall: Buen generalización (Diff = 0.0013)\n",
            "✅ Accuracy: Buen generalización (Diff = 0.0013)\n"
          ]
        }
      ],
      "source": [
        "# Análisis de overfitting\n",
        "print(\"\\n ANÁLISIS DE OVERFITTING:\")\n",
        "overfitting_threshold = 0.05  # Diferencia máxima aceptable\n",
        "\n",
        "for metric in metrics_to_display:\n",
        "    train_val = results['train_metrics'][metric]\n",
        "    test_val = results['test_metrics'][metric]\n",
        "    difference = abs(train_val - test_val)\n",
        "\n",
        "    if difference > overfitting_threshold:\n",
        "        print(f\" Posible overfitting en {metric}: Diff = {difference:.4f}\")\n",
        "    else:\n",
        "        print(f\"✅ {metric}: Buen generalización (Diff = {difference:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El modelo final demuestra un excelente rendimiento en términos de generalización, con diferencias mínimas entre las métricas de entrenamiento y prueba (todas inferiores al 0,23 %), lo que indica una efectiva prevención del sobreajuste. Un AUC-ROC de 0,7440 y una precisión del 82,88 % reflejan una capacidad predictiva sólida y consistente. \n",
        "\n",
        "Sin embargo, persiste un desafío crítico en el desequilibrio de clases: mientras que la clase mayoritaria (0) muestra un rendimiento excepcional con un recall del 98,85 % —capturando casi todos sus casos verdaderos—, la clase minoritaria (1) tiene un recall extremadamente bajo del 18,53 %, lo que significa que el modelo solo identifica correctamente menos de una quinta parte de los casos positivos reales.\n",
        "\n",
        "Esta disparidad significativa, que se evidencia en los 43 557 falsos negativos frente a los 9909 verdaderos positivos, indica que el modelo tiende a predecir la clase mayoritaria. Aunque las métricas agregadas son sólidas, el bajo índice de recuperación para la clase 1 limita considerablemente la utilidad del modelo en aplicaciones en las que la detección de casos positivos es crucial, como en el diagnóstico médico o la detección de fraudes, ya que los falsos negativos pueden tener consecuencias muy graves. Se recomienda implementar estrategias adicionales para abordar este desequilibrio, como ajustes en los umbrales de clasificación, técnicas de muestreo o ponderación de clases."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
